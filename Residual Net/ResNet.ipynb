{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAShONd6Q8hX",
        "outputId": "01134887-0756-4dc1-eb71-85f7efa7f0d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/learn/datasets\n",
            "/content/drive/My Drive/learn\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "FOLDERNAME = 'learn'\n",
        "assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
        "\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n",
        "\n",
        "%cd /content/drive/My\\ Drive/$FOLDERNAME/datasets/\n",
        "!bash get_datasets.sh\n",
        "%cd /content/drive/My\\ Drive/$FOLDERNAME"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import sampler\n",
        "\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as T\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "USE_GPU = True\n",
        "dtype = torch.float32\n",
        "\n",
        "if USE_GPU and torch.cuda.is_available():\n",
        "  device = torch.device('cuda')\n",
        "else:\n",
        "  device = torch.device('cpu')\n",
        "\n",
        "print_every = 100\n",
        "print('using device:', device)"
      ],
      "metadata": {
        "id": "MR5q7bCwRyG8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "984b6efb-1156-4148-a4dd-39aeba04c238"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "NUM_TRAIN = 49000\n",
        "\n",
        "transform = T.Compose([\n",
        "              T.ToTensor(),\n",
        "              T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "          ])\n",
        "\n",
        "cifar10_train = dset.CIFAR10('./datasets', train=True, download=True,\n",
        "                             transform=transform)\n",
        "loader_train = DataLoader(cifar10_train, batch_size = 64,\n",
        "                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN)))\n",
        "\n",
        "cifar10_val = dset.CIFAR10('./datasets', train=True, download=True,\n",
        "                             transform=transform)\n",
        "loader_val = DataLoader(cifar10_train, batch_size = 64,\n",
        "                          sampler=sampler.SubsetRandomSampler(range(NUM_TRAIN, 50000)))\n",
        "\n",
        "cifar10_test = dset.CIFAR10('./datasets', train=False, download=True,\n",
        "                             transform=transform)\n",
        "loader_test = DataLoader(cifar10_test, batch_size = 64)"
      ],
      "metadata": {
        "id": "S43lqhIDTjcm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_TINY_TRAIN = 5000\n",
        "NUM_TINY_VAL = 5200\n",
        "loader_train_tiny = DataLoader(cifar10_train, batch_size = 64,\n",
        "                               sampler=sampler.SubsetRandomSampler(range(NUM_TINY_TRAIN)))\n",
        "loader_val_tiny = DataLoader(cifar10_train, batch_size = 64,\n",
        "                             sampler=sampler.SubsetRandomSampler(range(NUM_TINY_TRAIN, NUM_TINY_VAL)))"
      ],
      "metadata": {
        "id": "oJyYnSPk1ZWu"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def flatten(x):\n",
        "  N = x.shape[0]\n",
        "  return x.view(N, -1)"
      ],
      "metadata": {
        "id": "GxSpPOnPULs-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_accuracy(loader, model):\n",
        "  if loader.dataset.train:\n",
        "      print('Checking accuracy on validation set')\n",
        "  else:\n",
        "      print('Checking accuracy on test set')\n",
        "\n",
        "  num_correct = 0\n",
        "  num_samples = 0\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "      for x, y in loader:\n",
        "          x = x.to(device=device, dtype=dtype)\n",
        "          y = y.to(device=device, dtype=torch.long)\n",
        "          scores = model(x)\n",
        "          _, preds = scores.max(1)\n",
        "          num_correct += (preds==y).sum()\n",
        "          num_samples += preds.size(0)\n",
        "      acc = float(num_correct) / num_samples\n",
        "      print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100*acc))"
      ],
      "metadata": {
        "id": "3PGWlrQWV89T"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, params, epochs=1):\n",
        "  model = model.to(device=device)\n",
        "  for e in range(epochs):\n",
        "      print(f\"epoch {e} / {epochs}:\")\n",
        "      for t, (x, y) in enumerate(loader_train):\n",
        "          model.train()\n",
        "          x = x.to(device=device, dtype=dtype)\n",
        "          y = y.to(device=device, dtype=torch.long)\n",
        "\n",
        "          scores = model(x)\n",
        "          loss = F.cross_entropy(scores, y)\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          if t % print_every == 0:\n",
        "            print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
        "            check_accuracy(loader_val, model)\n",
        "            print()"
      ],
      "metadata": {
        "id": "EILAB5HzUguf"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader_train_tiny"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fycmaq89O5zj",
        "outputId": "f26d90be-08d3-4cb3-824a-18e62d0541e7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7a5b585025a0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "class DeepNet(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_classes):\n",
        "    super().__init__()\n",
        "    self.w1 = nn.Linear(input_size, hidden_size[0])\n",
        "    nn.init.kaiming_normal_(self.w1.weight)\n",
        "    self.w2 = nn.Linear(hidden_size[0], hidden_size[1])\n",
        "    nn.init.kaiming_normal_(self.w1.weight)\n",
        "    self.w3 = nn.Linear(hidden_size[1], hidden_size[2])\n",
        "    nn.init.kaiming_normal_(self.w1.weight)\n",
        "    self.w4 = nn.Linear(hidden_size[2], hidden_size[3])\n",
        "    nn.init.kaiming_normal_(self.w1.weight)\n",
        "    self.w5 = nn.Linear(hidden_size[3], hidden_size[4])\n",
        "    nn.init.kaiming_normal_(self.w1.weight)\n",
        "    self.w6 = nn.Linear(hidden_size[4], num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = flatten(x)\n",
        "    x = F.relu(self.w1(x))\n",
        "    x = F.relu(self.w2(x))\n",
        "    x = F.relu(self.w3(x))\n",
        "    x = F.relu(self.w4(x))\n",
        "    x = F.relu(self.w5(x))\n",
        "    scores = self.w6(x)\n",
        "    return scores\n",
        "\n",
        "def testDeepNet():\n",
        "  input_size = 50\n",
        "  hidden_size = [100, 100, 100, 100, 100]\n",
        "  x = torch.zeros((64, input_size), dtype=dtype)\n",
        "  model = DeepNet(input_size, hidden_size, 10)\n",
        "  scores = model(x)\n",
        "  print(scores.size()) #[64, 10]\n",
        "testDeepNet()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGtoLcB7OUr-",
        "outputId": "ad475d46-1bc4-4519-aa40-99d3b42b66af"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 9e-4\n",
        "hidden_size = [256, 256, 128, 64, 32]\n",
        "\n",
        "model = DeepNet(3 * 32 * 32, hidden_size, 10)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "train(model, optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMsRLUW2RjOO",
        "outputId": "9f229a19-21a6-4acd-80c1-0f95f85a73d2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0, loss = 2.3208\n",
            "Checking accuracy on validation set\n",
            "Got 79 / 1000 correct (7.90)\n",
            "\n",
            "Iteration 100, loss = 1.8002\n",
            "Checking accuracy on validation set\n",
            "Got 335 / 1000 correct (33.50)\n",
            "\n",
            "Iteration 200, loss = 1.7219\n",
            "Checking accuracy on validation set\n",
            "Got 363 / 1000 correct (36.30)\n",
            "\n",
            "Iteration 300, loss = 1.7700\n",
            "Checking accuracy on validation set\n",
            "Got 404 / 1000 correct (40.40)\n",
            "\n",
            "Iteration 400, loss = 1.7041\n",
            "Checking accuracy on validation set\n",
            "Got 441 / 1000 correct (44.10)\n",
            "\n",
            "Iteration 500, loss = 1.5875\n",
            "Checking accuracy on validation set\n",
            "Got 436 / 1000 correct (43.60)\n",
            "\n",
            "Iteration 600, loss = 1.6532\n",
            "Checking accuracy on validation set\n",
            "Got 431 / 1000 correct (43.10)\n",
            "\n",
            "Iteration 700, loss = 1.5248\n",
            "Checking accuracy on validation set\n",
            "Got 473 / 1000 correct (47.30)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_classes):\n",
        "    super().__init__()\n",
        "    self.w1 = nn.Linear(input_size, hidden_size[0])\n",
        "    nn.init.kaiming_normal_(self.w1.weight)\n",
        "    self.w2 = nn.Linear(hidden_size[0], hidden_size[1])\n",
        "    nn.init.kaiming_normal_(self.w1.weight)\n",
        "    self.w3 = nn.Linear(hidden_size[1], hidden_size[2])\n",
        "    nn.init.kaiming_normal_(self.w1.weight)\n",
        "    self.w4 = nn.Linear(hidden_size[2], hidden_size[3])\n",
        "    nn.init.kaiming_normal_(self.w1.weight)\n",
        "    self.w5 = nn.Linear(hidden_size[3], hidden_size[4])\n",
        "    nn.init.kaiming_normal_(self.w1.weight)\n",
        "    self.w6 = nn.Linear(hidden_size[4], num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = flatten(x)\n",
        "    x = F.relu(self.w1(x)) + self.w1(x)\n",
        "    x = F.relu(self.w2(x)) + self.w2(x)\n",
        "    x = F.relu(self.w3(x)) + self.w3(x)\n",
        "    x = F.relu(self.w4(x)) + self.w4(x)\n",
        "    x = F.relu(self.w5(x)) + self.w5(x)\n",
        "    scores = self.w6(x) + self.w6(x)\n",
        "    return scores\n",
        "\n",
        "def testResNet():\n",
        "  input_size = 50\n",
        "  hidden_size = [100, 100, 100, 100, 100]\n",
        "  x = torch.zeros((64, input_size), dtype=dtype)\n",
        "  model = DeepNet(input_size, hidden_size, 10)\n",
        "  scores = model(x)\n",
        "  print(scores.size()) #[64, 10]\n",
        "testDeepNet()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2V-ofVKTUUE",
        "outputId": "17fbaab9-e871-460e-c17d-c6b23a51552c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 9e-4\n",
        "hidden_size = [256, 256, 128, 64, 32]\n",
        "\n",
        "model = ResNet(3 * 32 * 32, hidden_size, 10)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "train(model, optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiZXefQWU4XT",
        "outputId": "d638366d-9ba4-44c9-f62e-7e7c33d717c0"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0, loss = 3.4114\n",
            "Checking accuracy on validation set\n",
            "Got 170 / 1000 correct (17.00)\n",
            "\n",
            "Iteration 100, loss = 1.7818\n",
            "Checking accuracy on validation set\n",
            "Got 352 / 1000 correct (35.20)\n",
            "\n",
            "Iteration 200, loss = 2.1045\n",
            "Checking accuracy on validation set\n",
            "Got 370 / 1000 correct (37.00)\n",
            "\n",
            "Iteration 300, loss = 1.8096\n",
            "Checking accuracy on validation set\n",
            "Got 371 / 1000 correct (37.10)\n",
            "\n",
            "Iteration 400, loss = 1.5503\n",
            "Checking accuracy on validation set\n",
            "Got 397 / 1000 correct (39.70)\n",
            "\n",
            "Iteration 500, loss = 1.6976\n",
            "Checking accuracy on validation set\n",
            "Got 391 / 1000 correct (39.10)\n",
            "\n",
            "Iteration 600, loss = 1.7590\n",
            "Checking accuracy on validation set\n",
            "Got 411 / 1000 correct (41.10)\n",
            "\n",
            "Iteration 700, loss = 1.5825\n",
            "Checking accuracy on validation set\n",
            "Got 435 / 1000 correct (43.50)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet2(nn.Module):\n",
        "    def __init__(self, in_channel, channel_1, channel_2, num_classes):\n",
        "       super().__init__()\n",
        "       self.conv1 = nn.Conv2d(in_channel, channel_1, 5, padding=2, bias=True)\n",
        "       self.conv2 = nn.Conv2d(channel_1, channel_2, 3, padding=1, bias=True)\n",
        "       self.proj1 = nn.Conv2d(in_channel, channel_1, 5, padding=2, bias=False)\n",
        "       self.proj2 = nn.Conv2d(channel_1, channel_2, 3, padding=1, bias=False)\n",
        "       self.fc = nn.Linear(channel_2 * 32 * 32, num_classes, bias=False)\n",
        "       nn.init.kaiming_normal_(self.conv1.weight)\n",
        "       nn.init.kaiming_normal_(self.conv2.weight)\n",
        "       nn.init.kaiming_normal_(self.fc.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.conv2(F.relu(self.conv1(x))) + self.proj2(self.proj1(x))\n",
        "      x = F.relu(x)\n",
        "      x = flatten(x)\n",
        "      scores = self.fc(x)\n",
        "      return scores\n",
        "\n",
        "def testResNet2():\n",
        "    x = torch.zeros((64, 3, 32, 32), dtype=dtype)\n",
        "    model = ResNet2(3, 12, 8, 10)\n",
        "    scores = model(x)\n",
        "    print(scores.size())\n",
        "\n",
        "testResNet2()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQCbX0WFVV4N",
        "outputId": "a1cf7bee-4970-45d6-fba9-0b263c5007df"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 3e-3\n",
        "channel_1 = 32\n",
        "channel_2 = 16\n",
        "\n",
        "model = ResNet2(3, channel_1, channel_2, 10)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "train(model, optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZZal0rVWVtA",
        "outputId": "98b89995-6d62-4d28-f5da-86a02c4f79bc"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0, loss = 3.9482\n",
            "Checking accuracy on validation set\n",
            "Got 86 / 1000 correct (8.60)\n",
            "\n",
            "Iteration 100, loss = 1.7070\n",
            "Checking accuracy on validation set\n",
            "Got 330 / 1000 correct (33.00)\n",
            "\n",
            "Iteration 200, loss = 1.8507\n",
            "Checking accuracy on validation set\n",
            "Got 377 / 1000 correct (37.70)\n",
            "\n",
            "Iteration 300, loss = 1.7634\n",
            "Checking accuracy on validation set\n",
            "Got 412 / 1000 correct (41.20)\n",
            "\n",
            "Iteration 400, loss = 1.7366\n",
            "Checking accuracy on validation set\n",
            "Got 426 / 1000 correct (42.60)\n",
            "\n",
            "Iteration 500, loss = 1.5221\n",
            "Checking accuracy on validation set\n",
            "Got 466 / 1000 correct (46.60)\n",
            "\n",
            "Iteration 600, loss = 1.5241\n",
            "Checking accuracy on validation set\n",
            "Got 459 / 1000 correct (45.90)\n",
            "\n",
            "Iteration 700, loss = 1.5697\n",
            "Checking accuracy on validation set\n",
            "Got 372 / 1000 correct (37.20)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class ThreeLayerConvNet(nn.Module):\n",
        "    def __init__(self, in_channel, channel_1, channel_2, num_classes):\n",
        "       super().__init__()\n",
        "       self.conv1 = nn.Conv2d(in_channel, channel_1, 5, padding=2, bias=True)\n",
        "       self.conv2 = nn.Conv2d(channel_1, channel_2, 3, padding=1, bias=True)\n",
        "       self.fc = nn.Linear(channel_2 * 32 * 32, num_classes, bias=False)\n",
        "       nn.init.kaiming_normal_(self.conv1.weight)\n",
        "       nn.init.kaiming_normal_(self.conv2.weight)\n",
        "       nn.init.kaiming_normal_(self.fc.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = F.relu(self.conv1(x))\n",
        "      x = F.relu(self.conv2(x))\n",
        "      x = flatten(x)\n",
        "      scores = self.fc(x)\n",
        "      return scores\n",
        "\n",
        "def test_ThreadLayerConvNet():\n",
        "    x = torch.zeros((64, 3, 32, 32), dtype=dtype)\n",
        "    model = ThreeLayerConvNet(3, 12, 8, 10)\n",
        "    scores = model(x)\n",
        "    print(scores.size())\n",
        "\n",
        "test_ThreadLayerConvNet()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtY0ogiXWwGv",
        "outputId": "b2ff2326-89f8-493f-ca06-1def982155b9"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 3e-3\n",
        "channel_1 = 32\n",
        "channel_2 = 16\n",
        "\n",
        "model = ThreeLayerConvNet(3, channel_1, channel_2, 10)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "train(model, optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LimIDb1LX5IC",
        "outputId": "bac6f292-5c9b-4714-fa9c-4aa21738f325"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0, loss = 3.0150\n",
            "Checking accuracy on validation set\n",
            "Got 109 / 1000 correct (10.90)\n",
            "\n",
            "Iteration 100, loss = 2.2864\n",
            "Checking accuracy on validation set\n",
            "Got 145 / 1000 correct (14.50)\n",
            "\n",
            "Iteration 200, loss = 2.3062\n",
            "Checking accuracy on validation set\n",
            "Got 137 / 1000 correct (13.70)\n",
            "\n",
            "Iteration 300, loss = 2.1634\n",
            "Checking accuracy on validation set\n",
            "Got 231 / 1000 correct (23.10)\n",
            "\n",
            "Iteration 400, loss = 2.0540\n",
            "Checking accuracy on validation set\n",
            "Got 263 / 1000 correct (26.30)\n",
            "\n",
            "Iteration 500, loss = 1.8451\n",
            "Checking accuracy on validation set\n",
            "Got 285 / 1000 correct (28.50)\n",
            "\n",
            "Iteration 600, loss = 1.8052\n",
            "Checking accuracy on validation set\n",
            "Got 354 / 1000 correct (35.40)\n",
            "\n",
            "Iteration 700, loss = 1.6616\n",
            "Checking accuracy on validation set\n",
            "Got 382 / 1000 correct (38.20)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Block(nn.Module):\n",
        "  def __init__(self, in_channel, out_channel, stride=1):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channel, out_channel, kernel_size=3,\n",
        "                           stride=stride, padding=1, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(out_channel)\n",
        "    self.conv2 = nn.Conv2d(out_channel, out_channel, kernel_size=3,\n",
        "                           stride=1, padding=1, bias=False)\n",
        "    self.bn2 = nn.BatchNorm2d(out_channel)\n",
        "    self.shortcut = nn.Identity()\n",
        "    if stride != 1 or in_channel != out_channel:\n",
        "      self.shortcut = nn.Sequential(nn.Conv2d(in_channel, out_channel, kernel_size=1, stride=stride, bias=False),\n",
        "                                    nn.BatchNorm2d(out_channel))\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = F.relu(self.bn1(self.conv1(x)))\n",
        "    out = self.bn2(self.conv2(out))\n",
        "    out += self.shortcut(x)\n",
        "    out = F.relu(out)\n",
        "    return out\n",
        "\n",
        "def testblock():\n",
        "    x = torch.zeros((64, 3, 32, 32), dtype=dtype)  # minibatch size 64, image size [3, 32, 32]\n",
        "    model = Block(in_channel=3, out_channel=12, stride=1)\n",
        "    scores = model(x)\n",
        "    print(scores.size())\n",
        "testblock()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvOOPyswb4-U",
        "outputId": "054b8552-c0c3-4391-f40a-c9528d616512"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 12, 32, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet3(nn.Module):\n",
        "  def __init__(self, block):\n",
        "     super().__init__()\n",
        "     self.in_channel=64\n",
        "     self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "     self.bn1= nn.BatchNorm2d(64)\n",
        "     self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "     self.layer1 = self._make_block(block, 64, num_blocks[0], stride=1)\n",
        "     self.layer2 = self._make_block(block, 128, num_blocks[1], stride=2)\n",
        "     self.layer3 = self._make_block(block, 256, num_blocks[2], stride=2)\n",
        "     self.layer4 = self._make_block(block, 512, num_blocks[3], stride=2)\n",
        "     self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
        "     self.fc = nn.Linear(512, num_classes)\n",
        "\n",
        "  def _make_block(self, block, out_channel, blocks, stride):\n",
        "    layers = []\n",
        "    layers.append(block(self.in_channel, out_channel, stride))\n",
        "    self.in_channel = out_channel\n",
        "    for _ in range(1, blocks):\n",
        "      layers.append(block(out_channel, out_channel))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = F.relu(self.bn1(self.conv1(x)))\n",
        "    out = self.maxpool(out)\n",
        "    out = self.layer1(out)\n",
        "    out = self.layer2(out)\n",
        "    out = self.layer3(out)\n",
        "    out = self.layer4(out)\n",
        "    out = self.avgpool(out)\n",
        "    out = torch.flatten(out, 1)\n",
        "    out = self.fc(out)\n",
        "    return out\n",
        "\n",
        "\n",
        "num_classes=10\n",
        "num_blocks = [3, 4, 6, 3]\n",
        "def testResNet3():\n",
        "    x = torch.zeros((64, 3, 32, 32), dtype=dtype)\n",
        "    model = ResNet3(Block)\n",
        "    scores = model(x)\n",
        "    print(scores.size())\n",
        "\n",
        "testResNet3() # [64, 10]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPmwxNhJZMoa",
        "outputId": "83283c8f-3324-4bf9-d91b-70ae2716a6e9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 2e-4\n",
        "num_classes=10\n",
        "num_blocks = [3, 4, 6, 3]\n",
        "model = ResNet3(Block).to(device)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "print_every = 200\n",
        "train(model, optimizer, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUhQ_8W5k4ps",
        "outputId": "51d8a086-cf1f-43fd-dd3a-75d627a7089e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0 / 5:\n",
            "Iteration 0, loss = 2.5820\n",
            "Checking accuracy on validation set\n",
            "Got 112 / 1000 correct (11.20)\n",
            "\n",
            "Iteration 200, loss = 1.4906\n",
            "Checking accuracy on validation set\n",
            "Got 456 / 1000 correct (45.60)\n",
            "\n",
            "Iteration 400, loss = 1.2746\n",
            "Checking accuracy on validation set\n",
            "Got 510 / 1000 correct (51.00)\n",
            "\n",
            "Iteration 600, loss = 1.4656\n",
            "Checking accuracy on validation set\n",
            "Got 539 / 1000 correct (53.90)\n",
            "\n",
            "epoch 1 / 5:\n",
            "Iteration 0, loss = 0.9280\n",
            "Checking accuracy on validation set\n",
            "Got 575 / 1000 correct (57.50)\n",
            "\n",
            "Iteration 200, loss = 1.2993\n",
            "Checking accuracy on validation set\n",
            "Got 613 / 1000 correct (61.30)\n",
            "\n",
            "Iteration 400, loss = 1.2437\n",
            "Checking accuracy on validation set\n",
            "Got 604 / 1000 correct (60.40)\n",
            "\n",
            "Iteration 600, loss = 1.1063\n",
            "Checking accuracy on validation set\n",
            "Got 676 / 1000 correct (67.60)\n",
            "\n",
            "epoch 2 / 5:\n",
            "Iteration 0, loss = 0.7674\n",
            "Checking accuracy on validation set\n",
            "Got 652 / 1000 correct (65.20)\n",
            "\n",
            "Iteration 200, loss = 0.7208\n",
            "Checking accuracy on validation set\n",
            "Got 640 / 1000 correct (64.00)\n",
            "\n",
            "Iteration 400, loss = 0.9776\n",
            "Checking accuracy on validation set\n",
            "Got 667 / 1000 correct (66.70)\n",
            "\n",
            "Iteration 600, loss = 0.9059\n",
            "Checking accuracy on validation set\n",
            "Got 673 / 1000 correct (67.30)\n",
            "\n",
            "epoch 3 / 5:\n",
            "Iteration 0, loss = 0.6166\n",
            "Checking accuracy on validation set\n",
            "Got 668 / 1000 correct (66.80)\n",
            "\n",
            "Iteration 200, loss = 0.7233\n",
            "Checking accuracy on validation set\n",
            "Got 689 / 1000 correct (68.90)\n",
            "\n",
            "Iteration 400, loss = 0.9672\n",
            "Checking accuracy on validation set\n",
            "Got 719 / 1000 correct (71.90)\n",
            "\n",
            "Iteration 600, loss = 0.7386\n",
            "Checking accuracy on validation set\n",
            "Got 684 / 1000 correct (68.40)\n",
            "\n",
            "epoch 4 / 5:\n",
            "Iteration 0, loss = 0.6504\n",
            "Checking accuracy on validation set\n",
            "Got 674 / 1000 correct (67.40)\n",
            "\n",
            "Iteration 200, loss = 0.5560\n",
            "Checking accuracy on validation set\n",
            "Got 709 / 1000 correct (70.90)\n",
            "\n",
            "Iteration 400, loss = 0.6605\n",
            "Checking accuracy on validation set\n",
            "Got 688 / 1000 correct (68.80)\n",
            "\n",
            "Iteration 600, loss = 0.5013\n",
            "Checking accuracy on validation set\n",
            "Got 720 / 1000 correct (72.00)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Yevg_qiAlUwp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}